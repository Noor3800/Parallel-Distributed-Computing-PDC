{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrS7uhtMrKKD",
        "outputId": "6b9e9e8e-ebd2-45a2-e627-e7215581d516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Oct  6 18:00:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dqp4eOLtC_z"
      },
      "source": [
        "# Part 1 – Memory Allocation and Copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESNomeq-rreV",
        "outputId": "0f87f0da-5ab4-463a-db82-d25f5c74a5da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing part1_memory.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile part1_memory.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "    const int N = 8;  // small for display\n",
        "    float A[N], B[N];\n",
        "    for(int i=0;i<N;i++){ A[i]=i; B[i]=2*i; }\n",
        "\n",
        "    float *d_A, *d_B;\n",
        "    cudaMalloc(&d_A, N*sizeof(float));\n",
        "    cudaMalloc(&d_B, N*sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, A, N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    printf(\"=== Part 1: Memory Allocation ===\\\\n\");\n",
        "    printf(\"Host A: \"); for(int i=0;i<N;i++) printf(\"%.1f \", A[i]);\n",
        "    printf(\"\\\\nHost B: \"); for(int i=0;i<N;i++) printf(\"%.1f \", B[i]);\n",
        "    printf(\"\\\\nGPU memory allocated & data copied successfully.\\\\n\");\n",
        "\n",
        "    cudaFree(d_A); cudaFree(d_B);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UoSGqQlrubV",
        "outputId": "bb0e80d7-25c4-4994-8659-b0e36bf7359a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Part 1: Memory Allocation ===\\nHost A: 0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 \\nHost B: 0.0 2.0 4.0 6.0 8.0 10.0 12.0 14.0 \\nGPU memory allocated & data copied successfully.\\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 part1_memory.cu -o part1 && ./part1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUq0MYTOtKcj"
      },
      "source": [
        "# Part 2 – Serial Kernel Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIZMJ1AArweK",
        "outputId": "d8a9386e-6231-4026-a1dd-533f21f23aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing part2_serial.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile part2_serial.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void kernel1(float *A,float *B,float *C,int N){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<N) C[i]=A[i]+B[i];\n",
        "}\n",
        "__global__ void kernel2(float *C,float *D,int N){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<N) D[i]=C[i]*C[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N=8;\n",
        "    float A[N],B[N],C[N],D[N];\n",
        "    for(int i=0;i<N;i++){A[i]=i;B[i]=2*i;}\n",
        "\n",
        "    float *dA,*dB,*dC,*dD;\n",
        "    cudaMalloc(&dA,N*sizeof(float));\n",
        "    cudaMalloc(&dB,N*sizeof(float));\n",
        "    cudaMalloc(&dC,N*sizeof(float));\n",
        "    cudaMalloc(&dD,N*sizeof(float));\n",
        "\n",
        "    cudaMemcpy(dA,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB,B,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    kernel1<<<1,N>>>(dA,dB,dC,N);\n",
        "    kernel2<<<1,N>>>(dC,dD,N);\n",
        "    cudaMemcpy(D,dD,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"=== Part 2: Serial Execution ===\\\\nD: \");\n",
        "    for(int i=0;i<N;i++) printf(\"%.1f \",D[i]);\n",
        "    printf(\"\\\\n\");\n",
        "\n",
        "    cudaFree(dA);cudaFree(dB);cudaFree(dC);cudaFree(dD);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7anEDAvryZv",
        "outputId": "9adb92ea-523c-49a0-c6b8-a44841ccc684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mpart2_serial.cu(15)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"C\"\u001b[0m was declared but never referenced\n",
            "      float A[N],B[N],C[N],D[N];\n",
            "                      ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "=== Part 2: Serial Execution ===\\nD: 0.0 9.0 36.0 81.0 144.0 225.0 324.0 441.0 \\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 part2_serial.cu -o part2 && ./part2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc3N8FM-tTZu"
      },
      "source": [
        "# Part 3 – Streams and Race Conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSM6p7V7r0lC",
        "outputId": "9293dafa-a983-4b06-8d00-572ed61732a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing part3_streams.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile part3_streams.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void kernel1(float *A,float *B,float *C,int N){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<N) C[i]=A[i]+B[i];\n",
        "}\n",
        "__global__ void kernel2(float *C,float *D,int N){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<N) D[i]=C[i]*C[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N=8;\n",
        "    float A[N],B[N],C[N],D[N];\n",
        "    for(int i=0;i<N;i++){A[i]=i;B[i]=2*i;}\n",
        "\n",
        "    float *dA,*dB,*dC,*dD;\n",
        "    cudaMalloc(&dA,N*sizeof(float));\n",
        "    cudaMalloc(&dB,N*sizeof(float));\n",
        "    cudaMalloc(&dC,N*sizeof(float));\n",
        "    cudaMalloc(&dD,N*sizeof(float));\n",
        "    cudaMemcpy(dA,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB,B,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaStream_t s1,s2; cudaStreamCreate(&s1); cudaStreamCreate(&s2);\n",
        "    int half=N/2;\n",
        "\n",
        "    kernel1<<<1,half,0,s1>>>(dA,dB,dC,half);\n",
        "    kernel2<<<1,half,0,s1>>>(dC,dD,half);\n",
        "\n",
        "    kernel1<<<1,half,0,s2>>>(dA+half,dB+half,dC+half,half);\n",
        "    kernel2<<<1,half,0,s2>>>(dC+half,dD+half,half);\n",
        "\n",
        "    cudaStreamSynchronize(s1);\n",
        "    cudaStreamSynchronize(s2);\n",
        "    cudaMemcpy(D,dD,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"=== Part 3: Streams (safe split) ===\\\\nD: \");\n",
        "    for(int i=0;i<N;i++) printf(\"%.1f \",D[i]);\n",
        "    printf(\"\\\\n\");\n",
        "\n",
        "    cudaFree(dA);cudaFree(dB);cudaFree(dC);cudaFree(dD);\n",
        "    cudaStreamDestroy(s1);cudaStreamDestroy(s2);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlXxJ6ARr2lc",
        "outputId": "dfa4e041-ed2c-4621-a092-1269d2629843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mpart3_streams.cu(15)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"C\"\u001b[0m was declared but never referenced\n",
            "      float A[N],B[N],C[N],D[N];\n",
            "                      ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "=== Part 3: Streams (safe split) ===\\nD: 0.0 9.0 36.0 81.0 144.0 225.0 324.0 441.0 \\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 part3_streams.cu -o part3 && ./part3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zbJwvSftYg4"
      },
      "source": [
        "# Part 4 – Synchronization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGBvww9Qr4vO",
        "outputId": "4360d72c-4783-4ee2-f886-cb4f18f579ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing part4_sync.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile part4_sync.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void kernel(float *A,float *B,float *C,int N){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<N) C[i]=A[i]+B[i];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N=8;\n",
        "    float A[N],B[N],C[N]={0};\n",
        "    for(int i=0;i<N;i++){A[i]=i;B[i]=2*i;}\n",
        "    float *dA,*dB,*dC; cudaMalloc(&dA,N*sizeof(float));\n",
        "    cudaMalloc(&dB,N*sizeof(float)); cudaMalloc(&dC,N*sizeof(float));\n",
        "    cudaMemcpy(dA,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB,B,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    kernel<<<1,N>>>(dA,dB,dC,N);\n",
        "    // No cudaDeviceSynchronize() yet\n",
        "    cudaMemcpy(C,dC,N*sizeof(float),cudaMemcpyDeviceToHost); // may be incomplete\n",
        "    printf(\"=== Part 4: Without Sync ===\\\\nC: \");\n",
        "    for(int i=0;i<N;i++) printf(\"%.1f \",C[i]); printf(\"\\\\n\");\n",
        "\n",
        "    kernel<<<1,N>>>(dA,dB,dC,N);\n",
        "    cudaDeviceSynchronize(); // ensure finish\n",
        "    cudaMemcpy(C,dC,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "    printf(\"=== With cudaDeviceSynchronize() ===\\\\nC: \");\n",
        "    for(int i=0;i<N;i++) printf(\"%.1f \",C[i]); printf(\"\\\\n\");\n",
        "\n",
        "    cudaFree(dA);cudaFree(dB);cudaFree(dC);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozIOM1F7r6l6",
        "outputId": "cc130533-55ef-494b-8066-cc8090dd61ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Part 4: Without Sync ===\\nC: 0.0 3.0 6.0 9.0 12.0 15.0 18.0 21.0 \\n=== With cudaDeviceSynchronize() ===\\nC: 0.0 3.0 6.0 9.0 12.0 15.0 18.0 21.0 \\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 part4_sync.cu -o part4 && ./part4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsPy8cKUteah"
      },
      "source": [
        "# Part 5 – Thread Hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFuDgmDdr86J",
        "outputId": "5b246b0b-5df0-442b-b734-46192f47c4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing part5_threads.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile part5_threads.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void info(int N){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<8)\n",
        "    printf(\"blockIdx=%d threadIdx=%d -> i=%d\\\\n\",blockIdx.x,threadIdx.x,i);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  const int N=1024;\n",
        "  printf(\"=== Part 5: Thread hierarchy ===\\\\n<<<1,%d>>>:\\\\n\",N);\n",
        "  info<<<1,N>>>(N);\n",
        "  cudaDeviceSynchronize();\n",
        "  printf(\"\\\\n<<<%d,32>>>:\\\\n\",N/32);\n",
        "  info<<<N/32,32>>>(N);\n",
        "  cudaDeviceSynchronize();\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Fqhl_tr_Bf",
        "outputId": "7e3a2582-4117-4268-aa8e-421cb89a50e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Part 5: Thread hierarchy ===\\n<<<1,1024>>>:\\nblockIdx=0 threadIdx=0 -> i=0\\nblockIdx=0 threadIdx=1 -> i=1\\nblockIdx=0 threadIdx=2 -> i=2\\nblockIdx=0 threadIdx=3 -> i=3\\nblockIdx=0 threadIdx=4 -> i=4\\nblockIdx=0 threadIdx=5 -> i=5\\nblockIdx=0 threadIdx=6 -> i=6\\nblockIdx=0 threadIdx=7 -> i=7\\n\\n<<<32,32>>>:\\nblockIdx=0 threadIdx=0 -> i=0\\nblockIdx=0 threadIdx=1 -> i=1\\nblockIdx=0 threadIdx=2 -> i=2\\nblockIdx=0 threadIdx=3 -> i=3\\nblockIdx=0 threadIdx=4 -> i=4\\nblockIdx=0 threadIdx=5 -> i=5\\nblockIdx=0 threadIdx=6 -> i=6\\nblockIdx=0 threadIdx=7 -> i=7\\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 part5_threads.cu -o part5 && ./part5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stgdYwactikr"
      },
      "source": [
        "# Part 6 – Reduction (Shared Memory + atomicAdd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3yTveIPsBCO",
        "outputId": "b2c68e7a-7b95-4f4b-c27d-158bc01e9029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing part6_reduction.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile part6_reduction.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce(const float *in, float *out, int N){\n",
        "    extern __shared__ float s[];\n",
        "    int tid=threadIdx.x;\n",
        "    int i=blockIdx.x*blockDim.x*2+threadIdx.x;\n",
        "    float sum=0;\n",
        "    if(i<N) sum+=in[i];\n",
        "    if(i+blockDim.x<N) sum+=in[i+blockDim.x];\n",
        "    s[tid]=sum; __syncthreads();\n",
        "    for(int sSize=blockDim.x/2;sSize>0;sSize>>=1){\n",
        "        if(tid<sSize) s[tid]+=s[tid+sSize];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(tid==0) atomicAdd(out,s[0]);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N=1024;\n",
        "    float D[N]; for(int i=0;i<N;i++) D[i]=9*i*i;\n",
        "    float *dD,*dSum; cudaMalloc(&dD,N*sizeof(float)); cudaMalloc(&dSum,sizeof(float));\n",
        "    cudaMemcpy(dD,D,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemset(dSum,0,sizeof(float));\n",
        "    reduce<<<N/512,256,256*sizeof(float)>>>(dD,dSum,N);\n",
        "    cudaDeviceSynchronize();\n",
        "    float hostSum; cudaMemcpy(&hostSum,dSum,sizeof(float),cudaMemcpyDeviceToHost);\n",
        "    printf(\"=== Part 6: Reduction ===\\\\nSum of D = %.2f\\\\n\",hostSum);\n",
        "    cudaFree(dD); cudaFree(dSum);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfnO_3XwsDnN",
        "outputId": "2f676695-c87c-4ad8-f0da-156b3c9635e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Part 6: Reduction ===\\nSum of D = 3216508416.00\\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 part6_reduction.cu -o part6 && ./part6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THrE_LT8sF91"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
