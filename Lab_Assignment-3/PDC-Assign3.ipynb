{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQY4UbnKC2jM",
        "outputId": "d05d3cda-1573-40e5-f578-f8564b59ddd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mini_batch_train.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mini_batch_train.cu\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cmath>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define CHECK(call) { cudaError_t err = call; if(err!=cudaSuccess){ \\\n",
        "    fprintf(stderr,\"CUDA error %s:%d: %s\\n\",__FILE__,__LINE__,cudaGetErrorString(err)); exit(1);} }\n",
        "\n",
        "const int N=8;\n",
        "const int BATCH=4;\n",
        "const float ETA=0.1f;\n",
        "\n",
        "__global__ void forwardKernel(const float* x,const float* w,const float* bias,float* y,int n,int batch){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int b=blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  if(i<n && b<batch){\n",
        "    int idx=b*n+i;\n",
        "    float bi=bias?bias[i]:0.0f;\n",
        "    y[idx]=w[i]*x[idx]+bi;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void updateKernel(float* w,const float* x,const float* y,const float* t,int n,int batch,float eta){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<n){\n",
        "    float g=0.0f;\n",
        "    for(int b=0;b<batch;++b){\n",
        "      int idx=b*n+i;\n",
        "      float err=y[idx]-t[idx];\n",
        "      g+=err*x[idx];\n",
        "    }\n",
        "    g/=float(batch);\n",
        "    w[i]-=eta*g;\n",
        "  }\n",
        "}\n",
        "\n",
        "void printArray(const char* msg,const float* A,int n){\n",
        "  printf(\"%s\",msg);\n",
        "  for(int i=0;i<n;++i) printf(\" %.4f\",A[i]);\n",
        "  printf(\"\\n\");\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  printf(\"N=%d, BATCH=%d, ETA=%0.3f\\n\",N,BATCH,ETA);\n",
        "  const int total=N*BATCH;\n",
        "  float *hx=(float*)malloc(sizeof(float)*total);\n",
        "  float *hw=(float*)malloc(sizeof(float)*N);\n",
        "  float *hb=(float*)malloc(sizeof(float)*N);\n",
        "  float *ht=(float*)malloc(sizeof(float)*total);\n",
        "\n",
        "  for(int i=0;i<N;++i){ hw[i]=0.5f+0.1f*i; hb[i]=0.0f; }\n",
        "  for(int b=0;b<BATCH;++b)\n",
        "    for(int i=0;i<N;++i){\n",
        "      int idx=b*N+i;\n",
        "      hx[idx]=1.0f+0.5f*i+0.1f*b;\n",
        "      ht[idx]=(hw[i]*hx[idx])+0.5f;\n",
        "    }\n",
        "\n",
        "  printArray(\"Initial weights:\",hw,N);\n",
        "\n",
        "  float *dx,*dw,*db,*dt,*dy;\n",
        "  CHECK(cudaMalloc(&dx,sizeof(float)*total));\n",
        "  CHECK(cudaMalloc(&dw,sizeof(float)*N));\n",
        "  CHECK(cudaMalloc(&db,sizeof(float)*N));\n",
        "  CHECK(cudaMalloc(&dt,sizeof(float)*total));\n",
        "  CHECK(cudaMalloc(&dy,sizeof(float)*total));\n",
        "\n",
        "  CHECK(cudaMemcpy(dx,hx,sizeof(float)*total,cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(dw,hw,sizeof(float)*N,cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(db,hb,sizeof(float)*N,cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(dt,ht,sizeof(float)*total,cudaMemcpyHostToDevice));\n",
        "\n",
        "  dim3 blockF(8,4);\n",
        "  dim3 gridF((N+blockF.x-1)/blockF.x,(BATCH+blockF.y-1)/blockF.y);\n",
        "  int tpb=128; dim3 blockU((N<tpb)?N:tpb); dim3 gridU((N+blockU.x-1)/blockU.x);\n",
        "\n",
        "  printf(\"\\n--- Serial kernels (default stream) ---\\n\");\n",
        "  forwardKernel<<<gridF,blockF>>>(dx,dw,db,dy,N,BATCH);\n",
        "  updateKernel<<<gridU,blockU>>>(dw,dx,dy,dt,N,BATCH,ETA);\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "  CHECK(cudaMemcpy(hw,dw,sizeof(float)*N,cudaMemcpyDeviceToHost));\n",
        "  printArray(\"Weights after serial update:\",hw,N);\n",
        "\n",
        "  for(int i=0;i<N;++i) hw[i]=0.5f+0.1f*i;\n",
        "  CHECK(cudaMemcpy(dw,hw,sizeof(float)*N,cudaMemcpyHostToDevice));\n",
        "\n",
        "  printf(\"\\n--- Concurrent streams ---\\n\");\n",
        "  cudaStream_t s0,s1; CHECK(cudaStreamCreate(&s0)); CHECK(cudaStreamCreate(&s1));\n",
        "  forwardKernel<<<gridF,blockF,0,s0>>>(dx,dw,db,dy,N,BATCH);\n",
        "  updateKernel<<<gridU,blockU,0,s1>>>(dw,dx,dy,dt,N,BATCH,ETA);\n",
        "  CHECK(cudaStreamSynchronize(s0)); CHECK(cudaStreamSynchronize(s1));\n",
        "  CHECK(cudaMemcpy(hw,dw,sizeof(float)*N,cudaMemcpyDeviceToHost));\n",
        "  printArray(\"Weights after concurrent streams:\",hw,N);\n",
        "\n",
        "  CHECK(cudaStreamDestroy(s0)); CHECK(cudaStreamDestroy(s1));\n",
        "  cudaFree(dx); cudaFree(dw); cudaFree(db); cudaFree(dt); cudaFree(dy);\n",
        "  free(hx); free(hw); free(hb); free(ht);\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9IhHRmbeEJkW"
      },
      "outputs": [],
      "source": [
        "!nvcc mini_batch_train.cu -o mini_batch_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ5b_L1NELcY",
        "outputId": "6fe2e107-e9c0-477c-d639-e101b9210de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N=8, BATCH=4, ETA=0.100\n",
            "Initial weights: 0.5000 0.6000 0.7000 0.8000 0.9000 1.0000 1.1000 1.2000\n",
            "\n",
            "--- Serial kernels (default stream) ---\n",
            "Weights after serial update: 0.5000 0.6000 0.7000 0.8000 0.9000 1.0000 1.1000 1.2000\n",
            "\n",
            "--- Concurrent streams ---\n",
            "Weights after concurrent streams: 0.5000 0.6000 0.7000 0.8000 0.9000 1.0000 1.1000 1.2000\n"
          ]
        }
      ],
      "source": [
        "!./mini_batch_train"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
